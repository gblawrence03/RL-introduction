{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the car rental, there are much more states, actions and rewards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def poisson(n, lambd):\n",
    "    return (math.exp(-lambd) * lambd**n) / math.factorial(n)\n",
    "\n",
    "# We'll use this table to look up probabilities of car rentals and returns.\n",
    "# This is to optimise learning by avoiding repeated computation. \n",
    "poisson_table = dict()\n",
    "for n, lam in [(i, j) for i in range(21) for j in (2, 3, 4)]:\n",
    "    poisson_table[(n, lam)] = poisson(n, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [(i, j) for i in range(21) for j in range(21)]\n",
    "\n",
    "# Calculate the expected return of a state given the policy\n",
    "def state_action_value(action, state, values):\n",
    "    gamma = 0.9\n",
    "    if abs(action) > 5:\n",
    "        print(\"No more than 5 cars can be moved\")\n",
    "        return \n",
    "    # Move cars, clamp to 20 cars\n",
    "    init_nloc1 = min(state[0] - action, 20)\n",
    "    init_nloc2 = min(state[1] + action, 20)\n",
    "    base_reward = -2 * abs(action)\n",
    "    value = 0\n",
    "    # We now iterate through every possible combination of returned and requested cars to obtain an expected return. \n",
    "    for rented_loc1 in range(init_nloc1 + 1):\n",
    "        for rented_loc2 in range(init_nloc2 + 1):\n",
    "            new_init_nloc1 = init_nloc1 - rented_loc1\n",
    "            new_init_nloc2 = init_nloc2 - rented_loc2\n",
    "            reward = base_reward + 10 * (rented_loc1 + rented_loc2)\n",
    "            rented_prob = poisson_table[(rented_loc1, 3)] * poisson_table[(rented_loc2, 4)]\n",
    "            for returned_loc1 in range(20 - new_init_nloc1 + 1):\n",
    "                rented_prob_1 = rented_prob * poisson_table[(returned_loc1, 3)]\n",
    "                for returned_loc2 in range(20 - new_init_nloc2 + 1):\n",
    "                    nloc1 = new_init_nloc1 + returned_loc1\n",
    "                    nloc2 = new_init_nloc2 + returned_loc2\n",
    "                    # Get the probability of this new state occuring\n",
    "                    prob = rented_prob_1 * poisson_table[(returned_loc2, 2)]\n",
    "                    # Calculate the return based on the reward and the value of the new state\n",
    "                    value += prob * (reward + gamma * values[(nloc1, nloc2)])\n",
    "    return value\n",
    "\n",
    "def probability_state(rented_loc1, rented_loc2, returned_loc1, returned_loc2):\n",
    "    return poisson(rented_loc1, 3) * poisson(rented_loc2, 4) * poisson(returned_loc1, 3) * poisson(returned_loc2, 2)\n",
    "\n",
    "# Policy evaluation function\n",
    "def evaluate(accuracy, values, policy, iterations = None):\n",
    "    difference = accuracy\n",
    "    i = 0\n",
    "    while difference >= accuracy and (iterations == None or i < iterations):\n",
    "        difference = 0\n",
    "        t = time.time()\n",
    "        for s in states:\n",
    "            s_value = values[s]\n",
    "            values[s] = state_action_value(policy[s], s, values)\n",
    "            difference = max(difference, abs(s_value - values[s]))\n",
    "        print(f\"diff: {round(difference, 4)}, duration: {round(time.time() - t, 4)}\")\n",
    "        i += 1\n",
    "\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve(policy, values):\n",
    "    policy_stable = True\n",
    "    for s in states:\n",
    "        old_action = policy[s]\n",
    "        new_return = 0\n",
    "        for action in range(-1 * min(5, s[1]), min(5, s[0]) + 1):\n",
    "            val = state_action_value(action, s, values)\n",
    "            if val > new_return:\n",
    "                policy[s] = action\n",
    "                new_return = val\n",
    "            \n",
    "        if old_action != policy[s]:\n",
    "            policy_stable = False\n",
    "    return policy_stable, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(policy):\n",
    "    for loc1 in range(20, -1, -1):\n",
    "        for loc2 in range(0, 21):\n",
    "            print(f'{policy[(loc1, loc2)]}', end = '\\t')\n",
    "        print('\\n')\n",
    "\n",
    "def print_value(values):\n",
    "    for loc1 in range(20, -1, -1):\n",
    "        for loc2 in range(0, 21):\n",
    "            print(f'{round(values[(loc1, loc2)])}', end = '\\t')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: 128.6814, duration: 2.588\n",
      "diff: 88.9841, duration: 2.4293\n",
      "diff: 55.0557, duration: 2.4363\n",
      "diff: 30.8141, duration: 2.5141\n",
      "diff: 15.7996, duration: 2.423\n",
      "diff: 7.537, duration: 2.4373\n",
      "diff: 3.3714, duration: 2.4466\n",
      "diff: 1.4376, duration: 2.4615\n",
      "diff: 0.5861, duration: 2.4512\n",
      "diff: 0.2314, duration: 2.4502\n",
      "diff: 0.0895, duration: 2.4598\n",
      "diff: 0.0339, duration: 2.4291\n",
      "diff: 0.0126, duration: 2.4691\n",
      "diff: 0.0047, duration: 2.4238\n",
      "diff: 0.0017, duration: 2.4381\n",
      "diff: 0.0006, duration: 2.4383\n",
      "1\t3\t10\t22\t36\t51\t65\t77\t88\t97\t106\t113\t120\t126\t132\t137\t141\t143\t143\t139\t128\t\n",
      "\n",
      "1\t4\t13\t27\t45\t64\t82\t98\t112\t124\t136\t146\t155\t164\t171\t178\t183\t187\t187\t181\t168\t\n",
      "\n",
      "1\t5\t15\t31\t52\t74\t95\t115\t132\t147\t161\t174\t186\t196\t206\t214\t221\t225\t225\t219\t203\t\n",
      "\n",
      "1\t5\t16\t34\t57\t82\t105\t127\t147\t165\t181\t196\t210\t222\t234\t243\t252\t257\t257\t250\t231\t\n",
      "\n",
      "1\t5\t17\t36\t60\t86\t112\t136\t157\t177\t195\t212\t227\t241\t254\t266\t275\t281\t282\t274\t253\t\n",
      "\n",
      "1\t6\t17\t37\t62\t90\t116\t141\t164\t185\t205\t223\t240\t255\t269\t281\t291\t298\t299\t291\t269\t\n",
      "\n",
      "1\t6\t18\t38\t63\t91\t119\t145\t169\t191\t211\t230\t248\t264\t279\t292\t303\t310\t311\t303\t280\t\n",
      "\n",
      "1\t6\t18\t38\t64\t92\t120\t147\t171\t194\t215\t234\t253\t270\t285\t299\t310\t317\t319\t310\t287\t\n",
      "\n",
      "1\t6\t18\t38\t64\t93\t121\t147\t172\t195\t216\t236\t255\t272\t288\t302\t313\t321\t322\t314\t291\t\n",
      "\n",
      "1\t6\t18\t38\t64\t93\t121\t147\t172\t195\t216\t236\t255\t272\t288\t302\t313\t321\t322\t314\t290\t\n",
      "\n",
      "1\t6\t18\t38\t64\t92\t120\t147\t171\t194\t215\t234\t252\t269\t285\t298\t310\t317\t319\t310\t287\t\n",
      "\n",
      "1\t6\t18\t38\t63\t91\t119\t144\t168\t190\t211\t230\t247\t264\t279\t292\t303\t310\t311\t302\t280\t\n",
      "\n",
      "1\t6\t17\t37\t62\t89\t116\t141\t164\t185\t205\t223\t239\t255\t269\t281\t291\t298\t299\t291\t269\t\n",
      "\n",
      "1\t5\t17\t36\t60\t86\t112\t135\t157\t177\t195\t211\t227\t241\t254\t265\t274\t280\t281\t273\t253\t\n",
      "\n",
      "1\t5\t16\t33\t56\t81\t105\t126\t146\t164\t180\t195\t209\t221\t233\t243\t251\t256\t257\t249\t231\t\n",
      "\n",
      "1\t4\t14\t30\t50\t72\t93\t113\t130\t145\t159\t172\t183\t194\t203\t212\t219\t223\t223\t217\t201\t\n",
      "\n",
      "1\t4\t11\t25\t42\t60\t77\t93\t107\t119\t130\t140\t149\t157\t165\t171\t177\t180\t180\t175\t162\t\n",
      "\n",
      "0\t3\t8\t18\t30\t43\t56\t67\t77\t86\t94\t101\t107\t113\t118\t123\t126\t129\t129\t125\t116\t\n",
      "\n",
      "0\t1\t5\t10\t18\t25\t33\t40\t45\t51\t55\t59\t63\t66\t69\t72\t74\t76\t76\t73\t68\t\n",
      "\n",
      "0\t1\t2\t4\t7\t10\t14\t17\t19\t21\t23\t25\t27\t28\t29\t30\t31\t32\t32\t31\t29\t\n",
      "\n",
      "0\t0\t0\t1\t1\t2\t3\t4\t4\t5\t5\t6\t6\t6\t7\t7\t7\t7\t7\t7\t6\t\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m value \u001b[39m=\u001b[39m evaluate(\u001b[39m0.001\u001b[39m, value, policy)\n\u001b[0;32m     10\u001b[0m print_value(value)\n\u001b[1;32m---> 11\u001b[0m policy_stable, policy \u001b[39m=\u001b[39m improve(policy, value)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m print_policy(policy)\n",
      "Cell \u001b[1;32mIn[74], line 7\u001b[0m, in \u001b[0;36mimprove\u001b[1;34m(policy, values)\u001b[0m\n\u001b[0;32m      5\u001b[0m new_return \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39m5\u001b[39m, s[\u001b[39m1\u001b[39m]), \u001b[39mmin\u001b[39m(\u001b[39m5\u001b[39m, s[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     val \u001b[39m=\u001b[39m state_action_value(action, s, values)\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m val \u001b[39m>\u001b[39m new_return:\n\u001b[0;32m      9\u001b[0m         policy[s] \u001b[39m=\u001b[39m action\n",
      "Cell \u001b[1;32mIn[73], line 28\u001b[0m, in \u001b[0;36mstate_action_value\u001b[1;34m(action, state, values)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 prob \u001b[39m=\u001b[39m rented_prob \u001b[39m*\u001b[39m poisson_table[(returned_loc1, \u001b[39m3\u001b[39m)] \u001b[39m*\u001b[39m poisson_table[(returned_loc2, \u001b[39m2\u001b[39m)]\n\u001b[0;32m     27\u001b[0m                 \u001b[39m# Calculate the return based on the reward and the value of the new state\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m                 value \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prob \u001b[39m*\u001b[39m (reward \u001b[39m+\u001b[39m gamma \u001b[39m*\u001b[39m values[(nloc1, nloc2)])\n\u001b[0;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_stable = False\n",
    "policy = dict()\n",
    "value = dict()\n",
    "for state in states:\n",
    "    policy[state] = 0\n",
    "    value[state] = 0\n",
    "\n",
    "while not policy_stable:\n",
    "    value = evaluate(0.001, value, policy)\n",
    "    print_value(value)\n",
    "    policy_stable, policy = improve(policy, value)\n",
    "    print('\\n')\n",
    "    print_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
